# Model Configuration

# Forecast settings
forecast:
  horizons: [1, 7, 30]  # Days ahead to predict
  target: close         # close | log_close | return
  frequency: daily
  
# Feature engineering
features:
  lag_days: [1, 2, 3, 5, 7, 14, 21, 30]
  rolling_windows: [7, 14, 30, 60]
  rolling_stats: [mean, std, min, max]
  calendar_features: true
  volatility_features: true

# Train/test split
train_test_split:
  train_ratio: 0.8           # 80% train, 20% test
  min_test_days: 30          # Minimum test set size
  gap_days: 0                # Gap between train and test (avoid leakage)
  method: chronological      # chronological | walk_forward

# Backtesting
backtesting:
  method: walk_forward  # walk_forward | expanding | rolling
  initial_train_days: 252  # 1 year (lowered for shorter datasets like PVC)
  test_days: 30           # 1 month per fold
  step_days: 30           # Step forward 1 month
  
# Model hyperparameters
models:
  naive:
    enabled: true
    
  seasonal_naive:
    enabled: true
    season_length: 7  # Weekly seasonality
    
  arima:
    enabled: true
    auto_order: true
    max_p: 5
    max_d: 2
    max_q: 5
    
  ets:
    enabled: false
    
  xgboost:
    enabled: true
    params:
      n_estimators: 500
      max_depth: 6
      learning_rate: 0.05
      subsample: 0.8
      colsample_bytree: 0.8
      early_stopping_rounds: 50
      
  lightgbm:
    enabled: true
    params:
      n_estimators: 500
      max_depth: 6
      learning_rate: 0.05
      subsample: 0.8
      colsample_bytree: 0.8
      early_stopping_rounds: 50

  catboost:
    enabled: true
    params:
      iterations: 500
      depth: 6
      learning_rate: 0.05
      l2_leaf_reg: 3.0
      subsample: 0.8
      early_stopping_rounds: 50

  elasticnet:
    enabled: true
    params:
      alpha: 1.0
      l1_ratio: 0.5
      max_iter: 5000

  svr:
    enabled: true
    params:
      kernel: rbf
      C: 100.0
      epsilon: 0.1

  # Transformer models (Deep Learning)
  transformer:
    patchtst:
      enabled: true
      params:
        seq_len: 60
        patch_len: 10
        d_model: 64
        n_heads: 4
        n_layers: 2
        dropout: 0.1
        epochs: 50
        lr: 0.001
        batch_size: 32
        patience: 10
        
    tstransformer:
      enabled: false
      params:
        seq_len: 60
        d_model: 64
        epochs: 50

    itransformer:
      enabled: false
      params:
        seq_len: 60
        d_model: 64
        epochs: 50

    dlinear:
      enabled: true
      params:
        seq_len: 60
        moving_avg_kernel: 25
        individual: false
        epochs: 50
        lr: 0.001
        batch_size: 32
        patience: 10

    autoformer:
      enabled: false
      params:
        seq_len: 60
        d_model: 64
        n_heads: 4
        n_layers: 2
        moving_avg_kernel: 25
        epochs: 50

  # Pre-trained models (Foundation Models)
  pretrained:
    chronos:
      enabled: true
      params:
        model_id: "amazon/chronos-t5-small"
        finetune_epochs: 0
        context_length: 512
        
    lag_llama:
      enabled: false
      params:
        prediction_length: 30
        context_length: 512
        num_samples: 100

    moirai:
      enabled: false
      params:
        model_id: "Salesforce/moirai-1.1-R-small"
        prediction_length: 30
        context_length: 512
        num_samples: 100

    timer:
      enabled: false
      params:
        model_id: "thuml/timer-base-84m"
        context_length: 672
        prediction_length: 96

# Evaluation metrics
evaluation:
  primary_metric: mase  # mae | rmse | mape | mase | smape
  metrics: [mae, rmse, mape, mase, smape]

# MLflow tracking
mlflow:
  tracking_uri: mlruns
  experiment_name: commodity_forecast
  
# Inference settings
inference:
  batch_size: 100
  output_format: parquet  # parquet | csv | db
  output_path: data/predictions

# Future forecast settings
future_forecast:
  n_days: 30              # Default days to forecast
  confidence_level: 0.95  # 95% confidence interval
