# Commodity Price Prediction System

Há»‡ thá»‘ng dá»± Ä‘oÃ¡n giÃ¡ hÃ ng hÃ³a theo chuáº©n MLOps, há»— trá»£ nhiá»u máº·t hÃ ng vá»›i dá»¯ liá»‡u daily.

## ğŸš€ Quick Start

```bash
# Install dependencies
pip install -r requirements.txt

# Run training pipeline (ML models)
python -m src.training.trainer --commodity all

# Run training with Transformer models
python -m src.training.trainer --commodity all --model-type transformer

# Run training with pre-trained foundation models
python -m src.training.trainer --commodity all --model-type pretrained

# Run batch inference
python -m src.inference.predictor --date today
python -m src.inference.predictor --date today --model-type dlinear
```

## ğŸ““ Notebooks
- `notebook_demo_v2.ipynb`: **Advanced** â€” Transformer models, DLinear, Autoformer, fine-tuning, model comparison
- `notebook_demo.ipynb`: Original ML demo

## ğŸ“ Project Structure

```
commodity_forecast/
â”œâ”€â”€ configs/           # Configuration files
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/          # Bronze: Immutable raw data
â”‚   â”œâ”€â”€ processed/    # Silver: Cleaned data
â”‚   â””â”€â”€ features/     # Gold: Feature datasets
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/    # Data loading & validation
â”‚   â”œâ”€â”€ preprocessing/# Data cleaning
â”‚   â”œâ”€â”€ features/     # Feature engineering + sequence datasets
â”‚   â”œâ”€â”€ models/       # Model implementations (ML + Transformer + Pretrained)
â”‚   â”œâ”€â”€ training/     # Training pipeline + fine-tuning engine
â”‚   â”œâ”€â”€ inference/    # Batch prediction
â”‚   â”œâ”€â”€ evaluation/   # Metrics & backtesting
â”‚   â””â”€â”€ monitoring/   # Drift detection
â”œâ”€â”€ orchestration/    # Airflow DAGs
â”œâ”€â”€ serving/          # FastAPI
â”œâ”€â”€ notebooks/        # EDA & experiments
â””â”€â”€ tests/            # Unit & integration tests
```

## ğŸ“Š Supported Models

### Baseline & Statistical
- **Baseline**: Naive, Seasonal Naive
- **Statistical**: ARIMA, ETS

### Machine Learning
- **Gradient Boosting**: XGBoost, LightGBM, CatBoost
- **Linear**: ElasticNet
- **Kernel**: SVR

### Deep Learning (Lightweight Transformers)
| Model | Description | Best For |
|-------|------------|----------|
| **PatchTST** | Patch-based attention | Capturing local temporal patterns |
| **DLinear** | Decomposition + Linear | Fast baseline, often beats Transformers |
| **Autoformer** | Auto-Correlation + Decomposition | Periodic/seasonal patterns |
| **iTransformer** | Inverted attention (across features) | Multivariate correlated features |
| **TSTransformer** | Vanilla Transformer encoder | Simple Transformer baseline |

### Foundation Models (Pre-trained)
| Model | Source | Description |
|-------|--------|------------|
| **Chronos** | Amazon | T5-based probabilistic tokenized model |
| **Lag-Llama** | TS Foundation Models | LLM-inspired univariate probabilistic |
| **Moirai** | Salesforce | Universal multi-scale forecaster |
| **Timer** | Tsinghua | Generative pre-trained Transformer |

## ğŸ”§ Fine-tuning

The `TransformerFineTuner` provides production-quality fine-tuning:

```python
from src.training.finetuner import TransformerFineTuner

finetuner = TransformerFineTuner(
    model=model,
    lr=5e-5,
    epochs=10,
    warmup_steps=100,
    grad_accum_steps=2,
    use_amp=True,  # Mixed precision
)
train_loader, val_loader = finetuner.prepare_data(df, feature_cols)
results = finetuner.finetune(train_loader, val_loader)
```

## âš™ï¸ Configuration

Edit `configs/commodities.yaml` to add/modify commodities.
Edit `configs/model_config.yaml` for model hyperparameters.

## ğŸ“ˆ Metrics

- MAE (Mean Absolute Error)
- RMSE (Root Mean Square Error)
- MASE (Mean Absolute Scaled Error)
- sMAPE (Symmetric Mean Absolute Percentage Error)

## ğŸ³ Docker

```bash
docker build -t commodity-forecast .
docker run commodity-forecast python -m src.inference.predictor
```

## ğŸ“ License

MIT
